{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Flu Tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a simple demonstration on how open source Python libraries can be used to classify Twitter messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import necessary libraries.  We are using [scikit-learn](http://scikit-learn.org/stable/) to do most of the heavy lifting in terms of transforming and classifying data.  Scikit-learn contains a wide range of functions for performing data mining and classification tasks. We also use the [Pandas](https://pandas.pydata.org/) library for reading our data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working with any of the training data, we set up a classification [pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that combines all required data transformation and modeling steps:\n",
    "\n",
    "1. [Vectorize](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html): This step transforms text data into numerical data that can be used for classification.  You can read more [here](https://en.wikipedia.org/wiki/Bag-of-words_model).\n",
    "2. [TF-IDF](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html): This is an additional transformation that is common when working with text data.  It uses statistical properties of the dataset to assign weights to text terms.  You can read more [here](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).\n",
    "3. [Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html): Finally, we classify data that was transformed by the previous two steps.  In this case we are using a linear support vector classifier, which is commonly used in text classification tasks.  You can read more [here](https://en.wikipedia.org/wiki/Support_vector_machine#Linear_SVM). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read the training data Excel file, which has two columns:\n",
    "\n",
    "1. `text`: The text of the tweet.\n",
    "2. `valid`: A determination of whether this tweet indicates an actual case of influenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../training_set.xlsx\", \"Sheet1\")\n",
    "\n",
    "# the tweets are the input\n",
    "tweets = df.text.astype(str)\n",
    "\n",
    "# the 'valid' column is the desired output (is this tweet a valid flu tweet?)\n",
    "valid = df.valid.astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier with `tweets` as the input and `valid` as the output. **Note:** Because we created a classification pipeline, all of the data transformation and training is done in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "    ...lti_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the classifier\n",
    "classifier.fit(tweets, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can see how the trained classifier performs on new tweets by using the `predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i hate having the flu --> True\n",
      "i dont want to get a flu shot!! --> False\n",
      "the flu sucks, i keep coughing --> True\n",
      "Studies show that flu rates are rising in the nation: http://www.fakeurl.com --> False\n",
      "RT i have the flu!!! ahhh!!!! --> True\n",
      "just got a flu shot, but i hope i dont get the flu! --> False\n",
      "got a flu shot i better not get the flu now! --> True\n"
     ]
    }
   ],
   "source": [
    "# try it out on some sample tweets\n",
    "texts = [\n",
    "    'i hate having the flu', \n",
    "    'i dont want to get a flu shot!!', \n",
    "    'the flu sucks, i keep coughing', \n",
    "    'Studies show that flu rates are rising in the nation: http://www.fakeurl.com',\n",
    "    'RT i have the flu!!! ahhh!!!!',\n",
    "    'just got a flu shot, but i hope i dont get the flu!',\n",
    "    'got a flu shot i better not get the flu now!'\n",
    "]\n",
    "\n",
    "outputs = classifier.predict(texts)\n",
    "\n",
    "for text, output in zip(texts, outputs):\n",
    "    print('%s --> %s' % (text, str(output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Note:** Normally, you would perform [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html) on a model to evaluate its performance, but for this example we kept things simple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
